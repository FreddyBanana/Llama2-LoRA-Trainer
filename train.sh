python main.py \
	--MICRO_BATCH_SIZE 8 \
	--BATCH_SIZE 16 \
	--EPOCHS 10 \
	--LEARNING_RATE 5e-6 \
	--CONTEXT_LEN 64 \
	--TARGET_LEN 192 \
	--LORA_R 16 \
	--LORA_DROPOUT 0.2 \
	--MODEL_NAME TheBloke/Llama-2-7B-fp16 \
	--OUTPUT_DIR ./output_model \
	--DATA_PATH ./new_train.json \
	--DATA_TYPE json \
	--SAVE_STEPS 1000 \
	--BIT_4
